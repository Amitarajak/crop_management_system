# -*- coding: utf-8 -*-
"""tomato_disease_leaves.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ojba7XT9F2gIZVmgSbUOJTvLwZe2PbJf
"""

!pip install opendatasets
!pip install pandas

import opendatasets as od
import pandas

od.download("https://www.kaggle.com/datasets/farukalam/tomato-leaf-diseases-detection-computer-vision/data",force=True)

import os
import shutil

# Define the path to the dataset directory
dataset_dir = '/content/tomato-leaf-diseases-detection-computer-vision'

# Define the folders to remove from
folders_to_remove = ['test', 'train', 'valid']

# Loop through each folder and remove the 'labels' folder
for folder_name in folders_to_remove:
    folder_path = os.path.join(dataset_dir, folder_name)
    labels_folder_path = os.path.join(folder_path, 'labels')

    if os.path.exists(labels_folder_path):
        shutil.rmtree(labels_folder_path)
        print(f"Removed 'labels' folder from {folder_name} dataset.")
    else:
        print(f"'labels' folder not found in {folder_name} dataset.")

print("Data preprocessing completed successfully.")

od.download("https://www.kaggle.com/datasets/kaustubhb999/tomatoleaf/data")

od.download("https://www.kaggle.com/datasets/paulrosero/tomato-leaf-illness-detection",force=True)

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
import warnings
from tqdm import tqdm
from skimage.transform import resize
from skimage.io import imread
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score
from sklearn.linear_model import LogisticRegression
# Ignore all warnings
warnings.filterwarnings("ignore")

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/content/tomato-leaf-diseases-detection-computer-vision'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

len(os.listdir("/content/tomato-leaf-diseases-detection-computer-vision/train/images"))

len(os.listdir("/content/tomato-leaf-diseases-detection-computer-vision/valid/images"))

len(os.listdir("/content/tomato-leaf-diseases-detection-computer-vision/test/images"))

import os
import shutil

valid_dir = "/content/tomato-leaf-diseases-detection-computer-vision/valid/images"
train_dir = "/content/tomato-leaf-diseases-detection-computer-vision/train/images"
test_dir = "/content/tomato-leaf-diseases-detection-computer-vision/test/images"

# List files in the valid directory
valid_files = os.listdir(valid_dir)



# Determine the number of images to move to train and test folders
train_count = 31
test_count = 30

# Move images to train folder
for i in range(train_count):
    file_to_move = valid_files[i]
    source_path = os.path.join(valid_dir, file_to_move)
    destination_path = os.path.join(train_dir, file_to_move)
    shutil.move(source_path, destination_path)

# Move images to test folder
for i in range(train_count, train_count + test_count):
    file_to_move = valid_files[i]
    source_path = os.path.join(valid_dir, file_to_move)
    destination_path = os.path.join(test_dir, file_to_move)
    shutil.move(source_path, destination_path)


shutil.rmtree("/content/tomato-leaf-diseases-detection-computer-vision/valid")


print("Images moved to train and test folders. Valid folder dropped.")

len(os.listdir("/content/tomato-leaf-diseases-detection-computer-vision/train/images"))

len(os.listdir("/content/tomato-leaf-diseases-detection-computer-vision/test/images"))

import numpy as np
import pandas as pd



import os
for dirname, _, filenames in os.walk('/content/tomato-leaf-illness-detection'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

len(os.listdir("/content/tomato-leaf-illness-detection/dataset/train/dried_leaves"))

len(os.listdir("/content/tomato-leaf-illness-detection/dataset/train/healthy_leaves"))

len(os.listdir("/content/tomato-leaf-illness-detection/dataset/train/leaves_with_stains"))

len(os.listdir("/content/tomato-leaf-illness-detection/dataset/train/leaves_yellow_stains"))

import numpy as np
import pandas as pd



import os
for dirname, _, filenames in os.walk('/content/tomatoleaf'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

len(os.listdir("/content/tomatoleaf/tomato/train/Tomato___Bacterial_spot"))

!mv /content/tomato-leaf-diseases-detection-computer-vision/train/* /content/tomatoleaf/tomato/train

!mv /content/tomato-leaf-diseases-detection-computer-vision/test/* /content/tomatoleaf/tomato/val

!mv /content/tomato-leaf-illness-detection/dataset/train/* /content/tomatoleaf/tomato/train

!mv /content/tomato-leaf-illness-detection/dataset/test/* /content/tomatoleaf/tomato/val

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

train_dir = "/content/tomatoleaf/tomato/train"



img_width, img_height = 150, 150
batch_size = 32


train_datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')


train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')





model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(15, activation='softmax')
])


model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])


history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=10,

)


acc = history.history['accuracy']
loss = history.history['loss']


epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.title('Training accuracy ')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'r', label='Training loss')
plt.title('Training  loss')
plt.legend()
plt.show()

model.save("/content/saved_model.h5")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

test_dir = "/content/tomatoleaf/tomato/test"

test_datagen = ImageDataGenerator(rescale=1.0/255)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)


test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)
print("Test Accuracy:", test_accuracy)

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import os
import matplotlib.pyplot as plt
import random


model = load_model("/content/saved_model.h5")


class_labels = sorted(os.listdir(train_dir))


test_dir = "/content/tomatoleaf/tomato/test"


def preprocess_image(img_path, target_size=(150, 150)):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    return img_array


random_images = []
for _ in range(15):
    class_label = random.choice(class_labels)
    class_dir = os.path.join(test_dir, class_label)
    img_name = random.choice(os.listdir(class_dir))
    img_path = os.path.join(class_dir, img_name)
    random_images.append((img_path, class_label))


for img_path, true_label in random_images:
    img_array = preprocess_image(img_path)


    prediction = model.predict(img_array)
    predicted_class_idx = np.argmax(prediction)
    predicted_class_label = class_labels[predicted_class_idx]


    img = image.load_img(img_path)
    plt.imshow(img)
    plt.title(f"True Label: {true_label}, Predicted Label: {predicted_class_label}")
    plt.axis('off')
    plt.show()

from google.colab import drive


drive.mount('/content/drive')



from google.colab import files


uploaded = files.upload()

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import os


model = load_model("/content/saved_model.h5")

class_labels = sorted(os.listdir(train_dir))


def preprocess_image(img_path, target_size=(150, 150)):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    return img_array


downloaded_images_dir = "/content/drive/MyDrive/tomatoes"


downloaded_images = []


for filename in os.listdir(downloaded_images_dir):
    img_path = os.path.join(downloaded_images_dir, filename)
    img_array = preprocess_image(img_path)


    prediction = model.predict(img_array)
    predicted_class_idx = np.argmax(prediction)
    predicted_class_label = class_labels[predicted_class_idx]


    img = image.load_img(img_path)
    plt.imshow(img)
    plt.title(f"Predicted Class: {predicted_class_label}")
    plt.axis('off')
    plt.show()